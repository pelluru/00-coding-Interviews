{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem 079: 079 - DataFrame Basics: Drop challenge\n",
        "\n",
        "**Category:** DataFrame Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Schema\n",
        "```\n",
        "root\n",
        " |-- id: string\n",
        " |-- ts: timestamp\n",
        " |-- user_id: string\n",
        " |-- event_type: string\n",
        " |-- value: double\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql import SparkSession, functions as F\n",
        "from pyspark.sql.window import Window\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "res = events.select(\"id\", \"user_id\", \"event_type\", \"value\") \\    .withColumn(\"value_norm\", (F.col(\"value\") - F.mean(\"value\").over(Window.partitionBy()))/F.stddev_pop(\"value\").over(Window.partitionBy())) \\    .filter(F.col(\"event_type\") == \"purchase\")\n",
        "assert \"value_norm\" in res.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tests (chispa / SQL assertions)\n",
        "- Install `chispa` if desired: `pip install chispa`\n",
        "- Or run simple `res.count()` / schema checks."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}