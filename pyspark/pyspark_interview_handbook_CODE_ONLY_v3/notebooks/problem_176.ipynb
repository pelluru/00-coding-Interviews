{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Problem 176: 176 - MLlib Basics: Vectorassembler challenge\n",
        "\n",
        "**Category:** MLlib Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Schema\n",
        "```\n",
        "root\n",
        " |-- uid: string\n",
        " |-- name: string\n",
        " |-- email: string\n",
        " |-- country: string\n",
        " |-- signup_ts: timestamp\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.sql import SparkSession, functions as F\n",
        "from pyspark.sql.window import Window\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "label_indexer = StringIndexer(inputCol=\"event_type\", outputCol=\"label\", handleInvalid=\"skip\")\n",
        "assembler = VectorAssembler(inputCols=[\"value\"], outputCol=\"features\")\n",
        "lr = LogisticRegression(maxIter=10)\n",
        "model = Pipeline(stages=[label_indexer, assembler, lr]).fit(sessions)\n",
        "res = model.transform(sessions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tests (chispa / SQL assertions)\n",
        "- Install `chispa` if desired: `pip install chispa`\n",
        "- Or run simple `res.count()` / schema checks."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}